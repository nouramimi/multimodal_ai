import os
import logging
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image
import io
import re

load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    raise ValueError(
        "‚ùå GOOGLE_API_KEY not found!\n"
        "Please create a .env file with: GOOGLE_API_KEY=your_key_here"
    )

genai.configure(api_key=GOOGLE_API_KEY)
logger = logging.getLogger(__name__)


class ImageAnalyzer:
    
    def __init__(self, model_name='gemini-2.0-flash-exp'):
        self.model = genai.GenerativeModel(model_name)
    
    def extract_image_content(self, image_data):
        
        try:
            # Convertir en PIL Image
            image = self._load_image(image_data)
            
            # Prompt d'extraction pr√©cise
            extraction_prompt = """Analyse cette image et d√©cris EXACTEMENT ce que tu vois.

R√àGLES STRICTES:
1. Si l'image contient du TEXTE (capture d'√©cran, document, test, article):
   ‚Üí Transcris TOUT le texte, mot √† mot, ligne par ligne
   ‚Üí Pr√©serve la structure et les titres
   
2. Si c'est une PHOTO/IMAGE sans texte:
   ‚Üí D√©cris la sc√®ne, les objets, les personnes de mani√®re factuelle
   
3. Si c'est un GRAPHIQUE/DIAGRAMME:
   ‚Üí Explique sa structure et son contenu

NE FAIS AUCUNE INTERPR√âTATION CR√âATIVE. Sois FACTUEL."""
            
            response = self.model.generate_content([extraction_prompt, image])
            return response.text
            
        except Exception as e:
            logger.error(f"Image extraction error: {e}")
            return f"‚ùå Erreur d'extraction: {str(e)}"
    
    def _load_image(self, image_data):
        
        if isinstance(image_data, Image.Image):
            return image_data
        elif isinstance(image_data, bytes):
            return Image.open(io.BytesIO(image_data))
        elif isinstance(image_data, str):  # Chemin de fichier
            return Image.open(image_data)
        else:
            raise ValueError(f"Format d'image non support√©: {type(image_data)}")



class PromptBuilder:
    
    
    @staticmethod
    def build_video_timeline(frame_captions, duration):
        
        if not frame_captions:
            return ""
        
        timeline = []
        frame_interval = duration / len(frame_captions) if len(frame_captions) > 0 else duration
        
        for i, caption in enumerate(frame_captions):
            timestamp = int(i * frame_interval)
            minutes, seconds = timestamp // 60, timestamp % 60
            timeline.append(f"[{minutes:02d}:{seconds:02d}] {caption}")
        
        return "\n".join(timeline)
    
    @staticmethod
    def build_video_analysis_prompt(user_message, frame_captions, video_metadata):
        
        duration = video_metadata.get('duration', 0)
        timeline = PromptBuilder.build_video_timeline(frame_captions, duration)
        
        return f"""Tu es un assistant sympathique qui analyse des vid√©os. R√©ponds en FRAN√áAIS de mani√®re naturelle et conversationnelle.

L'utilisateur demande: "{user_message}"

Voici ce que j'ai vu dans la vid√©o ({duration//60}min {duration%60}s):

{timeline}

COMMENT R√âPONDRE:
‚úÖ Commence directement par r√©pondre (ex: "Cette vid√©o parle de...")
‚úÖ Utilise des paragraphes courts et a√©r√©s
‚úÖ Ajoute des √©mojis pour clarifier (üìö üéØ üí° üé• ‚ú®)
‚úÖ Sois naturel, comme si tu parlais √† un ami
‚úÖ Mets en gras les points importants avec **texte**

‚ùå NE COMMENCE PAS par "Okay", "Absolutely", "Here's", "Let me"
‚ùå N'utilise PAS de titres anglais
‚ùå Ne fais PAS de liste num√©rot√©e rigide type "1. Type de contenu"

R√©ponds maintenant de fa√ßon claire et engageante en FRAN√áAIS !"""

    @staticmethod
    def build_image_analysis_prompt(user_message, image_content):
        """Prompt d'analyse d'image conversationnel"""
        return f"""Tu es un assistant sympathique. L'utilisateur a partag√© une image avec ce message: "{user_message}"

üì∏ CONTENU DE L'IMAGE:
{image_content}

COMMENT R√âPONDRE:
‚úÖ R√©ponds en FRAN√áAIS de mani√®re naturelle
‚úÖ Si c'est du texte: r√©sume et commente le contenu
‚úÖ Si c'est une photo: d√©cris ce que tu vois
‚úÖ Utilise des paragraphes courts et des √©mojis üìå üí° ‚ú®
‚úÖ Sois direct et pertinent

‚ùå Ne commence PAS par "Okay", "Absolutely", "Here's"
‚ùå Pas de format trop structur√©

R√©ponds naturellement !"""

    @staticmethod
    def build_text_only_prompt(user_message):
        """Prompt pour le chat texte simple"""
        return f"""Tu es un assistant sympathique et intelligent. R√©ponds en FRAN√áAIS de mani√®re naturelle.

Message de l'utilisateur: "{user_message}"

R√àGLES:
‚úÖ R√©ponds de fa√ßon claire et conversationnelle
‚úÖ Utilise des paragraphes courts
‚úÖ Ajoute des √©mojis si √ßa aide (üìå üí° ‚ú® üéØ)
‚úÖ Sois pr√©cis mais accessible

‚ùå Ne commence PAS par "Okay", "Absolutely", "Certainly"
‚ùå √âvite le jargon inutile
‚ùå Pas de format trop formel

R√©ponds maintenant !"""

    @staticmethod
    def build_mixed_media_prompt(user_message, images=None, videos=None):
        """Prompt pour m√©dias mixtes conversationnel"""
        context_parts = []
        
        if images:
            context_parts.append(f"üì∏ {len(images)} image(s) partag√©e(s):")
            for i, content in enumerate(images, 1):
                context_parts.append(f"\nImage {i}:")
                context_parts.append(f"{content[:300]}...")
        
        if videos:
            context_parts.append(f"\nüé• {len(videos)} vid√©o(s) partag√©e(s):")
            for i, video_data in enumerate(videos, 1):
                caps = video_data['captions']
                dur = video_data['metadata'].get('duration', 0)
                context_parts.append(f"\nVid√©o {i} ({dur}s):")
                
                sample_size = min(3, len(caps))
                for j in range(sample_size):
                    context_parts.append(f"  ‚Üí {caps[j][:80]}")
        
        return f"""Tu es un assistant sympathique. R√©ponds en FRAN√áAIS de mani√®re naturelle.

L'utilisateur demande: "{user_message}"

{chr(10).join(context_parts)}

COMMENT R√âPONDRE:
‚úÖ Analyse ces m√©dias de mani√®re claire et naturelle
‚úÖ Utilise des √©mojis et des paragraphes courts
‚úÖ Sois direct et pertinent

‚ùå Pas de format trop formel
‚ùå Ne commence pas par "Okay" ou "Absolutely"

R√©ponds maintenant !"""



class ConversationMemory:
    
    
    def __init__(self, max_messages=10):
        self.messages = []
        self.max_messages = max_messages
    
    def add_message(self, role, content):
        
        self.messages.append({"role": role, "content": content})
        
        if len(self.messages) > self.max_messages * 2:
            self.messages = self.messages[-self.max_messages * 2:]
    
    def get_history_context(self):
        
        if not self.messages:
            return ""
        
        history_lines = ["Historique r√©cent:"]
        for msg in self.messages[-6:]:
            role = "User" if msg["role"] == "user" else "AI"
            content = msg["content"][:150]
            if len(msg["content"]) > 150:
                content += "..."
            history_lines.append(f"{role}: {content}")
        
        return "\n".join(history_lines) + "\n\n"
    
    def clear(self):
        
        self.messages = []



class MultimodalChatbot:
   
    def __init__(self, session_id):
        
        logger.info(f"Initializing chatbot for session: {session_id}")
        
        self.session_id = session_id
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        self.memory = ConversationMemory(max_messages=10)
        self.prompt_builder = PromptBuilder()
        self.image_analyzer = ImageAnalyzer()
        
        logger.info("Chatbot initialized successfully")
    
    def _clean_response(self, response_text):
        
        unwanted_patterns = [
            r'^(Okay|Absolutely|Certainly|Sure|Of course)[,!.\s]+',
            r'^(Here\'s|Here is|Let me|I\'ll)[,\s]+',
            r'^(D\'accord|Tr√®s bien|Bien s√ªr)[,!.\s]+'
        ]
        
        for pattern in unwanted_patterns:
            response_text = re.sub(pattern, '', response_text, flags=re.IGNORECASE)
        
        response_text = re.sub(r'\n{3,}', '\n\n', response_text)
        
        return response_text.strip()
    
    def _generate_response(self, prompt, include_history=True):
        
        try:
            if include_history:
                history_context = self.memory.get_history_context()
                full_prompt = f"{history_context}{prompt}"
            else:
                full_prompt = prompt
            
            response = self.model.generate_content(full_prompt)
            response_text = response.text
            
            # Nettoyer la r√©ponse
            response_text = self._clean_response(response_text)
            
            return response_text
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return f"D√©sol√©, une erreur s'est produite: {str(e)}"
    
    def chat_text_only(self, user_message):
        """Chat texte simple avec prompt am√©lior√©"""
        logger.info(f"Processing text: {user_message[:50]}...")
        
        prompt = self.prompt_builder.build_text_only_prompt(user_message)
        
        response_text = self._generate_response(prompt)
        
        self.memory.add_message("user", user_message)
        self.memory.add_message("assistant", response_text)
        
        logger.info("Text response generated")
        return response_text
    
    def chat_with_image(self, user_message, image_data):
        
        logger.info("Processing image message (improved method)")
        
        try:
            
            image_content = self.image_analyzer.extract_image_content(image_data)
            logger.info(f"Image content extracted: {len(image_content)} chars")
            
            
            prompt = self.prompt_builder.build_image_analysis_prompt(
                user_message,
                image_content
            )
            
            
            response_text = self._generate_response(prompt)
            
            
            self.memory.add_message("user", f"[Image] {user_message}")
            self.memory.add_message("assistant", response_text)
            
            logger.info("Image response generated")
            return response_text
            
        except Exception as e:
            logger.error(f"Error in chat_with_image: {e}")
            return f"‚ùå Erreur lors de l'analyse de l'image: {str(e)}"
    
    def chat_with_image_direct(self, user_message, image_data):
        
        logger.info("Processing image message (direct method)")
        
        try:
            
            if isinstance(image_data, bytes):
                image = Image.open(io.BytesIO(image_data))
            elif isinstance(image_data, str):
                image = Image.open(image_data)
            else:
                image = image_data
            
            
            history_context = self.memory.get_history_context()
            prompt = f"""{history_context}
L'utilisateur a partag√© une image avec ce message: "{user_message}"

Analyse l'image et r√©ponds en FRAN√áAIS de mani√®re naturelle:
- Si elle contient du TEXTE: lis-le attentivement
- Si c'est un test/article: identifie le sujet
- R√©ponds de mani√®re pr√©cise et pertinente
- Utilise des √©mojis pour clarifier

‚ùå Ne commence PAS par "Okay", "Absolutely", "Here's" """
            
            
            response = self.model.generate_content([prompt, image])
            response_text = self._clean_response(response.text)
            
            self.memory.add_message("user", f"[Image] {user_message}")
            self.memory.add_message("assistant", response_text)
            
            logger.info("Direct image response generated")
            return response_text
            
        except Exception as e:
            logger.error(f"Error in chat_with_image_direct: {e}")
            return f"‚ùå Erreur: {str(e)}"
    
    def chat_with_video(self, user_message, frame_captions, video_metadata):
        
        logger.info(f"Processing video: {len(frame_captions)} frames")
        
        logger.info(f"First caption preview: {frame_captions[0][:100] if frame_captions else 'EMPTY'}")
        logger.info(f"Video metadata: {video_metadata}")
        
        prompt = self.prompt_builder.build_video_analysis_prompt(
            user_message,
            frame_captions,
            video_metadata
        )
        
        logger.info(f"Prompt preview: {prompt[:300]}...")
        
        response_text = self._generate_response(prompt, include_history=False)
        
        logger.info(f"Response preview: {response_text[:100]}...")
        
        duration = video_metadata.get('duration', 0)
        self.memory.add_message("user", f"[Video {duration}s] {user_message}")
        self.memory.add_message("assistant", response_text)
        
        logger.info("Video response generated")
        return response_text
    
    def chat_with_mixed_media(self, user_message, images=None, videos=None):
        """Chat avec m√©dias mixtes"""
        logger.info("Processing mixed media")
        
        processed_images = []
        if images:
            for img_data in images:
                content = self.image_analyzer.extract_image_content(img_data)
                processed_images.append(content)
        
        prompt = self.prompt_builder.build_mixed_media_prompt(
            user_message,
            images=processed_images,
            videos=videos
        )
        
        response_text = self._generate_response(prompt, include_history=False)
        
        self.memory.add_message("user", f"[Mixed media] {user_message}")
        self.memory.add_message("assistant", response_text)
        
        logger.info("Mixed media response generated")
        return response_text
    
    def clear_history(self):
        """Effacer l'historique"""
        self.memory.clear()
        logger.info(f"History cleared for session {self.session_id}")